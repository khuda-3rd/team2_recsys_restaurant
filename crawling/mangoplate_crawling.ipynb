{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f24d7fe",
   "metadata": {},
   "source": [
    "# 필요한 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cfd5e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[K     |████████████████████████████████| 293 kB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy!=1.24.0,>=1.17 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from seaborn) (2.0.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/nomyeong-eun/Library/Python/3.9/lib/python/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.15.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9887c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7924f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys # 시스템\n",
    "import os  # 시스템\n",
    "\n",
    "# 데이터 다루기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# selenium 크롤링\n",
    "from selenium import webdriver  \n",
    "from selenium.webdriver import ActionChains as AC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 크롬 드라이버\n",
    "#import chromedriver_autoinstaller\n",
    "\n",
    "# beautifulsoup 크롤링\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# lxml 크롤링\n",
    "import lxml.html\n",
    "\n",
    "# 시간 조절\n",
    "import time\n",
    "\n",
    "# 시간 측정\n",
    "from tqdm import notebook\n",
    "\n",
    "# 정규표현식\n",
    "import re\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c802de8",
   "metadata": {},
   "source": [
    "# 망고플레이트 웹크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c20a454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = Service('../chromedriver/chromedriver.exe')\n",
    "\n",
    "\n",
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(service=ser)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "#driver2 = webdriver.Chrome(service=ser)  # for Windows\n",
    "#driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f45935fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f3b010ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [store, review]\n",
       "Index: []"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['store', 'review']\n",
    "df1 = pd.DataFrame(columns=columns)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43980477",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=2'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df2 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속합니다\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링합니다\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('span', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    # 평가 정보('맛있다' 마크)를 가져옵니다.\n",
    "    #review_recommend_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__Rating RestaurantReviewItem__Rating--Ok\"})\n",
    "    \n",
    "    # 리뷰를 가져옵니다.\n",
    "    review_text_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__ReviewContent\"})\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, review_text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df2 = df2.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bd20a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[금동양꼬치]</td>\n",
       "      <td>\\n          식당도 전체적으로 시끄럽지 않은 분위기이고 양꼬치와 소꼬치 모...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[라메이즈마라탕]</td>\n",
       "      <td>\\n          &lt;라메이즈 영통점&gt;잊지말자 이곳은 계란볶음밥 진리이다!마라탕,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[머내]</td>\n",
       "      <td>\\n          반신반의하며 갔지만 생각보다 만족\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[아름다운땅]</td>\n",
       "      <td>\\n\"정석적인 느낌의 음식점으로, 내부도 연식이 느껴지는 양식. 맛은 그냥..\"그래...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[중국미식성]</td>\n",
       "      <td>\\n          망고플레이스 실망 양고기 꼬치는 두가지를 시켰는데꼬치고기에서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[류참치]</td>\n",
       "      <td>\\n          무난.리필가능.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[칭따오양꼬치]</td>\n",
       "      <td>\\n          건두부무침 은근 맛있네요지인 집에 놀러갔는데 여기가 맛있다고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[베이커리카페 에이블리]</td>\n",
       "      <td>\\n          1. 계획엔 없었는데 이동 전에 배 채우고 가자는 의견이 있어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[고기잡이]</td>\n",
       "      <td>\\n          영통 제일 남도음식점의 냉이 넣은 새조개 샤브샤브. 밑반찬이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[어글리스토브]</td>\n",
       "      <td>\\n          이때 가을? 맞이해서 시푸드 페스티발 이런거 하고 있더라구요!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[돼지새마을본부]</td>\n",
       "      <td>\\n          무난무난한 돼지 특수부위집 ~- 돼지 특수부위를 합리적인 가격...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[아웃백스테이크하우스]</td>\n",
       "      <td>\\n          저희 집 아이들이 제일 좋아하는 곳이에요~ 아웃백 빵이랑 초코...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[김복남맥주]</td>\n",
       "      <td>\\n          먹태나 떡볶기에 간단히 맥주 한 잔하기 좋은 곳입니다.\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[쿠로이시로]</td>\n",
       "      <td>\\n          여기서 마셨던 커피가 그리워서 다녀왔어요. 역시나 커피는 맛나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[카페아라]</td>\n",
       "      <td>\\n          오랜만에 다시 방문한 카페 아라.수족관과 상어가 있는 이색 카...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[방촌양고기]</td>\n",
       "      <td>\\n          냄새 안나고 맛있어요ㅎㅎ매장도 깔끔하고  친절하시네요ㅎㅎ\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[하코야라멘]</td>\n",
       "      <td>\\n          꺄.... 여기 너무 좋아요ㅠㅠ 돈코츠라멘은 진짜 하루건너 먹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[앙코르보아]</td>\n",
       "      <td>\\n          생강라떼. 생각외로 꽤 진하고 맛있었다. 다만 오래 머무르기엔...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            store                                             review\n",
       "0         [금동양꼬치]  \\n          식당도 전체적으로 시끄럽지 않은 분위기이고 양꼬치와 소꼬치 모...\n",
       "1       [라메이즈마라탕]  \\n          <라메이즈 영통점>잊지말자 이곳은 계란볶음밥 진리이다!마라탕,...\n",
       "2            [머내]           \\n          반신반의하며 갔지만 생각보다 만족\\n        \n",
       "3         [아름다운땅]  \\n\"정석적인 느낌의 음식점으로, 내부도 연식이 느껴지는 양식. 맛은 그냥..\"그래...\n",
       "4         [중국미식성]  \\n          망고플레이스 실망 양고기 꼬치는 두가지를 시켰는데꼬치고기에서 ...\n",
       "5           [류참치]                     \\n          무난.리필가능.\\n        \n",
       "6        [칭따오양꼬치]  \\n          건두부무침 은근 맛있네요지인 집에 놀러갔는데 여기가 맛있다고 ...\n",
       "7   [베이커리카페 에이블리]  \\n          1. 계획엔 없었는데 이동 전에 배 채우고 가자는 의견이 있어...\n",
       "8          [고기잡이]  \\n          영통 제일 남도음식점의 냉이 넣은 새조개 샤브샤브. 밑반찬이 ...\n",
       "9        [어글리스토브]  \\n          이때 가을? 맞이해서 시푸드 페스티발 이런거 하고 있더라구요!...\n",
       "10      [돼지새마을본부]  \\n          무난무난한 돼지 특수부위집 ~- 돼지 특수부위를 합리적인 가격...\n",
       "11   [아웃백스테이크하우스]  \\n          저희 집 아이들이 제일 좋아하는 곳이에요~ 아웃백 빵이랑 초코...\n",
       "12        [김복남맥주]  \\n          먹태나 떡볶기에 간단히 맥주 한 잔하기 좋은 곳입니다.\\n  ...\n",
       "13        [쿠로이시로]  \\n          여기서 마셨던 커피가 그리워서 다녀왔어요. 역시나 커피는 맛나...\n",
       "14         [카페아라]  \\n          오랜만에 다시 방문한 카페 아라.수족관과 상어가 있는 이색 카...\n",
       "15        [방촌양고기]  \\n          냄새 안나고 맛있어요ㅎㅎ매장도 깔끔하고  친절하시네요ㅎㅎ\\n ...\n",
       "16        [하코야라멘]  \\n          꺄.... 여기 너무 좋아요ㅠㅠ 돈코츠라멘은 진짜 하루건너 먹...\n",
       "17        [앙코르보아]  \\n          생강라떼. 생각외로 꽤 진하고 맛있었다. 다만 오래 머무르기엔..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea0cf8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=3'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df3 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속합니다\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링합니다\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('span', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    # 평가 정보('맛있다' 마크)를 가져옵니다.\n",
    "    #review_recommend_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__Rating RestaurantReviewItem__Rating--Ok\"})\n",
    "    \n",
    "    # 리뷰를 가져옵니다.\n",
    "    review_text_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__ReviewContent\"})\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, review_text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df3 = df3.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc4e3422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[일일양]</td>\n",
       "      <td>\\n          좋아하는 양갈비집, 분위기도 서비스도 너무 좋다하이볼 양갈비 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[팔선생]</td>\n",
       "      <td>\\n          중식이 땡겨 들어온 팔선생. 사천새우와 자장면, 짬뽕을 주문했...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[겐코]</td>\n",
       "      <td>\\n          차디찬 완숙 계란 올려준 이후로 안 감처음 오픈했을 때 생각하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[우교당]</td>\n",
       "      <td>\\n          순메밀 100% 순면 가격이 9천원 비빔도 골동냉면도 9천원 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[매드테이블스]</td>\n",
       "      <td>\\n          수제 맥주와 칵테일을 즐길 수 있는 펍마침 안주 50%할인 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[쿄쿄식당]</td>\n",
       "      <td>\\n          항상 줄이 길어서 못갔다가 오늘은 자리가 남아서 가본 쿄쿄. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[작은집이자카야]</td>\n",
       "      <td>\\n          스끼야끼 말고 사시미와 메로 소금구이 리뷰. 사실 이곳은 스끼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[대박횟집]</td>\n",
       "      <td>\\n          킹크랩, 참치 배꼽살 머리살 특별 주문 메뉴로, 메뉴판에 없다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[코메타포레스트]</td>\n",
       "      <td>\\n          김치볶음밥 담백하게 맛있네요~\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[우세]</td>\n",
       "      <td>\\n          간단하게 먹으려구 들어왔는데 꿀대구 진짜진짜 추천합니다! 사장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[타누키돈부리]</td>\n",
       "      <td>\\n          존ㅡ맛 그냥 가성비 오짐서울에도있었으면\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[코이라멘]</td>\n",
       "      <td>\\n          괜찮은 것 같음\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[하추다방]</td>\n",
       "      <td>\\n          컨셉이 재밌고 독특해서 자주가요!당연히 맛도 있어요!자주 가는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[쿠시카츠쿠마]</td>\n",
       "      <td>\\n          쿠시카츠가 유명하지만 나고야식 테바사키로도 유명한 곳. 테바사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[이수국밥]</td>\n",
       "      <td>\\n          여기 기복있네지난번 좋은 기억이 있어 찾아갔다.마땅히 갈만한 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[머내]</td>\n",
       "      <td>\\n          영통 맛집 머내영통사는 친구들이 추천해줘서 작년쯤에 갔었는데 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[환이네뭉티기]</td>\n",
       "      <td>\\n          이게 뭉티기라는 거구나….뭉티기… 사실 이름만 들었을 뿐 잘 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[화포식당]</td>\n",
       "      <td>\\n          돼지고기 먹을때는 항상 이 집에 가려고 한다. 여러집많지만 분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[소울돼지갈비]</td>\n",
       "      <td>\\n          생긴지 얼마 안된 돼지갈비집. 원래 가던 곳이 불 빼는걸 재촉...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        store                                             review\n",
       "0       [일일양]  \\n          좋아하는 양갈비집, 분위기도 서비스도 너무 좋다하이볼 양갈비 ...\n",
       "1       [팔선생]  \\n          중식이 땡겨 들어온 팔선생. 사천새우와 자장면, 짬뽕을 주문했...\n",
       "2        [겐코]  \\n          차디찬 완숙 계란 올려준 이후로 안 감처음 오픈했을 때 생각하...\n",
       "3       [우교당]  \\n          순메밀 100% 순면 가격이 9천원 비빔도 골동냉면도 9천원 ...\n",
       "4    [매드테이블스]  \\n          수제 맥주와 칵테일을 즐길 수 있는 펍마침 안주 50%할인 이...\n",
       "5      [쿄쿄식당]  \\n          항상 줄이 길어서 못갔다가 오늘은 자리가 남아서 가본 쿄쿄. ...\n",
       "6   [작은집이자카야]  \\n          스끼야끼 말고 사시미와 메로 소금구이 리뷰. 사실 이곳은 스끼...\n",
       "7      [대박횟집]  \\n          킹크랩, 참치 배꼽살 머리살 특별 주문 메뉴로, 메뉴판에 없다...\n",
       "8   [코메타포레스트]             \\n          김치볶음밥 담백하게 맛있네요~\\n        \n",
       "9        [우세]  \\n          간단하게 먹으려구 들어왔는데 꿀대구 진짜진짜 추천합니다! 사장...\n",
       "10   [타누키돈부리]        \\n          존ㅡ맛 그냥 가성비 오짐서울에도있었으면\\n        \n",
       "11     [코이라멘]                     \\n          괜찮은 것 같음\\n        \n",
       "12     [하추다방]  \\n          컨셉이 재밌고 독특해서 자주가요!당연히 맛도 있어요!자주 가는...\n",
       "13   [쿠시카츠쿠마]  \\n          쿠시카츠가 유명하지만 나고야식 테바사키로도 유명한 곳. 테바사...\n",
       "14     [이수국밥]  \\n          여기 기복있네지난번 좋은 기억이 있어 찾아갔다.마땅히 갈만한 ...\n",
       "15       [머내]  \\n          영통 맛집 머내영통사는 친구들이 추천해줘서 작년쯤에 갔었는데 ...\n",
       "16   [환이네뭉티기]  \\n          이게 뭉티기라는 거구나….뭉티기… 사실 이름만 들었을 뿐 잘 ...\n",
       "17     [화포식당]  \\n          돼지고기 먹을때는 항상 이 집에 가려고 한다. 여러집많지만 분...\n",
       "18   [소울돼지갈비]  \\n          생긴지 얼마 안된 돼지갈비집. 원래 가던 곳이 불 빼는걸 재촉..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=4'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df4 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속합니다\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링합니다\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('span', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    # 평가 정보('맛있다' 마크)를 가져옵니다.\n",
    "    #review_recommend_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__Rating RestaurantReviewItem__Rating--Ok\"})\n",
    "    \n",
    "    # 리뷰를 가져옵니다.\n",
    "    review_text_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__ReviewContent\"})\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, review_text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df4 = df4.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08854b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[짠]</td>\n",
       "      <td>\\n          #영통#술집\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[아티제]</td>\n",
       "      <td>\\n          얼그레이쉬폰얼그레이 향이 은.은.하게 느껴지기도 하고 시트가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[갯마을산낙지]</td>\n",
       "      <td>\\n          영통 먹자골목에 위치한 낙지 전문점. 장흥, 신안에서 공수한 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[훌리스다이너]</td>\n",
       "      <td>\\n          영통 반달공원 근처 미국식 브런치 가게. 분위기에 끌려 방문했...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[일향죽]</td>\n",
       "      <td>\\n          인생죽집.사실 한평생 살면서 죽 별로 안좋아한다는 말을 달고살...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[맥시모부리또]</td>\n",
       "      <td>\\n          진짜 별로에요 ㅠㅠ사장님이 최악으로 불친절하고 가격은 엄청 비...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[포케올데이]</td>\n",
       "      <td>\\n          배달로도 시켜 먹기 좋은 포케집. 인테리어에 돈을 꽤나 쓴듯 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[꿀꿀이네곱창볶음]</td>\n",
       "      <td>\\n          .\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[때지]</td>\n",
       "      <td>\\n          때지.... 고기는 영통 최고인듯.   인정합니다. \\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[소담촌]</td>\n",
       "      <td>\\n          엄마께서 좋아라 하시는 샤브샤브 집 반반 육수도 가능하고요고기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[대덕골보쌈칼국수]</td>\n",
       "      <td>\\n          221009.딸 한테 저녁으로 뭐 먹고 싶어? 물어보니 유튜브...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[죠스떡볶이]</td>\n",
       "      <td>\\n          맛있어요 튀김 엄청 바삭하고 오뎅국물이 끝내줍니다 떡볶이는 별...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[라조이아]</td>\n",
       "      <td>\\n          영통은 이탈리안 음식점이 참 비싼 것 같아요근데 이 근처에 맛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[세종참숯돼지갈비]</td>\n",
       "      <td>\\n          영통 먹자골목 근처에 있는 돼지갈비집. 근처를 지날 때마다 항...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[파전한판]</td>\n",
       "      <td>\\n          영통역 근처 골목에 위치한 전집. 전에 막걸리가 먹고 싶어서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[봉평메밀]</td>\n",
       "      <td>\\n          오래된 메밀국수 맛집이에요~ 수원 처음 와서부터 쭉 방문하는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[밀크로프]</td>\n",
       "      <td>\\n            영통의 밀크로프!! ㅋㅋㅋ동네에 있는 애정하는 빵집이에요&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[영포화로]</td>\n",
       "      <td>\\n          평일 저녁에도 웨이팅이 있는 곳- 단점은 고기를 직접 구워야 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[블랙101]</td>\n",
       "      <td>\\n          어떤 카페를 갈까 걸어가며 구경하던 중 푸릇푸릇한 외관이 눈에...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         store                                             review\n",
       "0          [짠]                       \\n          #영통#술집\\n        \n",
       "1        [아티제]  \\n          얼그레이쉬폰얼그레이 향이 은.은.하게 느껴지기도 하고 시트가 ...\n",
       "2     [갯마을산낙지]  \\n          영통 먹자골목에 위치한 낙지 전문점. 장흥, 신안에서 공수한 ...\n",
       "3     [훌리스다이너]  \\n          영통 반달공원 근처 미국식 브런치 가게. 분위기에 끌려 방문했...\n",
       "4        [일향죽]  \\n          인생죽집.사실 한평생 살면서 죽 별로 안좋아한다는 말을 달고살...\n",
       "5     [맥시모부리또]  \\n          진짜 별로에요 ㅠㅠ사장님이 최악으로 불친절하고 가격은 엄청 비...\n",
       "6      [포케올데이]  \\n          배달로도 시켜 먹기 좋은 포케집. 인테리어에 돈을 꽤나 쓴듯 ...\n",
       "7   [꿀꿀이네곱창볶음]                            \\n          .\\n        \n",
       "8         [때지]  \\n          때지.... 고기는 영통 최고인듯.   인정합니다. \\n   ...\n",
       "9        [소담촌]  \\n          엄마께서 좋아라 하시는 샤브샤브 집 반반 육수도 가능하고요고기...\n",
       "10  [대덕골보쌈칼국수]  \\n          221009.딸 한테 저녁으로 뭐 먹고 싶어? 물어보니 유튜브...\n",
       "11     [죠스떡볶이]  \\n          맛있어요 튀김 엄청 바삭하고 오뎅국물이 끝내줍니다 떡볶이는 별...\n",
       "12      [라조이아]  \\n          영통은 이탈리안 음식점이 참 비싼 것 같아요근데 이 근처에 맛...\n",
       "13  [세종참숯돼지갈비]  \\n          영통 먹자골목 근처에 있는 돼지갈비집. 근처를 지날 때마다 항...\n",
       "14      [파전한판]  \\n          영통역 근처 골목에 위치한 전집. 전에 막걸리가 먹고 싶어서 ...\n",
       "15      [봉평메밀]  \\n          오래된 메밀국수 맛집이에요~ 수원 처음 와서부터 쭉 방문하는 ...\n",
       "16      [밀크로프]  \\n            영통의 밀크로프!! ㅋㅋㅋ동네에 있는 애정하는 빵집이에요<...\n",
       "17      [영포화로]  \\n          평일 저녁에도 웨이팅이 있는 곳- 단점은 고기를 직접 구워야 ...\n",
       "18     [블랙101]  \\n          어떤 카페를 갈까 걸어가며 구경하던 중 푸릇푸릇한 외관이 눈에..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=5'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df5 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속합니다\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링합니다\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('span', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    # 평가 정보('맛있다' 마크)를 가져옵니다.\n",
    "    #review_recommend_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__Rating RestaurantReviewItem__Rating--Ok\"})\n",
    "    \n",
    "    # 리뷰를 가져옵니다.\n",
    "    review_text_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__ReviewContent\"})\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, review_text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df5 = df5.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83d51b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[시래기담다]</td>\n",
       "      <td>\\n          수원 망포역 2번 출구 부근에 위치한 고등어 시래기밥 한상 (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[황소가한우곱창]</td>\n",
       "      <td>\\n          음... 곱창골목에서 주차장이 바로 옆에 있길래 일단 가봤다!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[양푼애등갈비]</td>\n",
       "      <td>\\n          요기 완전 찐맛집!매운갈비찜이 땡기던 어느 비오는 날.친구 추...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[데이비드커피랩]</td>\n",
       "      <td>\\n          장점 : 장소가 매우 쾌적함, 보타닉한 느낌이 산뜻함, 모임을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[수타원]</td>\n",
       "      <td>\\n          2018-11-17짬뽕 국물 짜지 않고 해산물도 신선했음. 자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[슝띠마라탕]</td>\n",
       "      <td>\\n          배달로 먹은 마라탕 중에 제일이어서 일부러 찾아가 먹은 가게....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[무물]</td>\n",
       "      <td>\\n          가성비, 맛, 안 갈 이유가 없는 곳새로 오픈한 해산물 전문 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[청기와감자탕]</td>\n",
       "      <td>\\n          오랜만에 뼈해장국이 갑자기 땡겨서 친구랑 다녀온 청기와뼈해장국...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[후이후이]</td>\n",
       "      <td>\\n          고코스 1인 30,000크리스피롤새우샐러드/유산슬/깐풍중새우/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[하울즈]</td>\n",
       "      <td>\\n          영통 반달공원 근처에 있는 카페. 식사후 골목을 걷다 분위기 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[핏제리아도우 by ppk]</td>\n",
       "      <td>\\n          영통 반달공원 근처에 있는 화덕피자집. 배달로 먹었는데 맛있어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[미소곱창]</td>\n",
       "      <td>\\n          무기가 있어도 기본이 안되면 뭘해도 안됩니다.진짜 유명한 곳이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[용궁잔치]</td>\n",
       "      <td>\\n          화덕생선구이를 좋아하지만 집주변에 마땅한곳이없어서 후기평좋아 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[오성수산]</td>\n",
       "      <td>\\n          와..이곳 분위기 무엇 ..? 영통 중심상가 3층에 위치해있어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[김명자낙지마당]</td>\n",
       "      <td>\\n          낙지는 역시 여기... 낙지찜을 드디어 먹어보았다간단하게는 낙...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[고쿠텐]</td>\n",
       "      <td>\\n          혼자 갔는데 1인석이 많아서 좋았습니다 가게 인테리어도 깔끔해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[홍루이젠]</td>\n",
       "      <td>\\n          맛있었어요 먹기도 간편하고 바쁠때 간식거리로 딱입니다. \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[구이몽]</td>\n",
       "      <td>\\n          #구이몽#영통\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              store                                             review\n",
       "0           [시래기담다]  \\n          수원 망포역 2번 출구 부근에 위치한 고등어 시래기밥 한상 (...\n",
       "1         [황소가한우곱창]  \\n          음... 곱창골목에서 주차장이 바로 옆에 있길래 일단 가봤다!...\n",
       "2          [양푼애등갈비]  \\n          요기 완전 찐맛집!매운갈비찜이 땡기던 어느 비오는 날.친구 추...\n",
       "3         [데이비드커피랩]  \\n          장점 : 장소가 매우 쾌적함, 보타닉한 느낌이 산뜻함, 모임을...\n",
       "4             [수타원]  \\n          2018-11-17짬뽕 국물 짜지 않고 해산물도 신선했음. 자...\n",
       "5           [슝띠마라탕]  \\n          배달로 먹은 마라탕 중에 제일이어서 일부러 찾아가 먹은 가게....\n",
       "6              [무물]  \\n          가성비, 맛, 안 갈 이유가 없는 곳새로 오픈한 해산물 전문 ...\n",
       "7          [청기와감자탕]  \\n          오랜만에 뼈해장국이 갑자기 땡겨서 친구랑 다녀온 청기와뼈해장국...\n",
       "8            [후이후이]  \\n          고코스 1인 30,000크리스피롤새우샐러드/유산슬/깐풍중새우/...\n",
       "9             [하울즈]  \\n          영통 반달공원 근처에 있는 카페. 식사후 골목을 걷다 분위기 ...\n",
       "10  [핏제리아도우 by ppk]  \\n          영통 반달공원 근처에 있는 화덕피자집. 배달로 먹었는데 맛있어...\n",
       "11           [미소곱창]  \\n          무기가 있어도 기본이 안되면 뭘해도 안됩니다.진짜 유명한 곳이...\n",
       "12           [용궁잔치]  \\n          화덕생선구이를 좋아하지만 집주변에 마땅한곳이없어서 후기평좋아 ...\n",
       "13           [오성수산]  \\n          와..이곳 분위기 무엇 ..? 영통 중심상가 3층에 위치해있어...\n",
       "14        [김명자낙지마당]  \\n          낙지는 역시 여기... 낙지찜을 드디어 먹어보았다간단하게는 낙...\n",
       "15            [고쿠텐]  \\n          혼자 갔는데 1인석이 많아서 좋았습니다 가게 인테리어도 깔끔해...\n",
       "16           [홍루이젠]  \\n          맛있었어요 먹기도 간편하고 바쁠때 간식거리로 딱입니다. \\n ...\n",
       "17            [구이몽]                      \\n          #구이몽#영통\\n        "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=6'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df6 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속합니다\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링합니다\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('span', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    # 평가 정보('맛있다' 마크)를 가져옵니다.\n",
    "    #review_recommend_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__Rating RestaurantReviewItem__Rating--Ok\"})\n",
    "    \n",
    "    # 리뷰를 가져옵니다.\n",
    "    review_text_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__ReviewContent\"})\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, review_text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df6 = df6.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b1bc476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[만고쿠]</td>\n",
       "      <td>\\n          가게이름 : #만고쿠 영통점⠀위치 : 수원시 영통구 반달로7번...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[츠키]</td>\n",
       "      <td>\\n          연어가 맛있어요 케이퍼도 같이 주셔서 좋았습니다. 오뎅탕은 그...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[지호한방삼계탕]</td>\n",
       "      <td>\\n          .\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[남문통닭]</td>\n",
       "      <td>\\n          달콤하고 맛있어요.시원한 맥주와 함께하니 잘어울리는 맛\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[993COFFEE]</td>\n",
       "      <td>\\n          경국/영통 여러분!!!!! 쥬씨말고 엄마가 정말 갈아주신듯힌 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[라헬의부엌]</td>\n",
       "      <td>\\n          일찍 문여는 카페라 엄마들 모임하기 좋아요. 브런치 메뉴도 맛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[소담골]</td>\n",
       "      <td>\\n          팥죽  맛있다고해서 처음 가본곳입니다식당에 키오스크 기계로 선...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[쿠지라]</td>\n",
       "      <td>\\n          텐동에 탄산이랑 먹으면 진짜 천국임\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[구스띠모]</td>\n",
       "      <td>\\n          가격대비 별로..젤라또라고하기도 그렇고 그냥 베라먹는게 나은듯...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[얜시부]</td>\n",
       "      <td>\\n          처음으로 먹었을 땐 별로였는데 재료 신중히 선택하니 맛있어짐재...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[물고기자리]</td>\n",
       "      <td>\\n          수지에서 시작된 물고기자리 체인점. 한 때 숙성회 무한리필이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[고기육심]</td>\n",
       "      <td>\\n          아파트 단지 입구에 있는 고깃집. 산책을 하다가 미친듯한 양념...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[서월]</td>\n",
       "      <td>\\n          영통역 먹자골목에 있는 이자카야. 신상 이자카야가 생겼길래 궁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[짬뽕타임]</td>\n",
       "      <td>\\n          평범함탕수육 진짜 많이 줌\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[교동반점짬뽕]</td>\n",
       "      <td>\\n          차돌짬뽕(9000), 군만두(5000).로-칼 맛집입니다. 주...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[앳더블루]</td>\n",
       "      <td>\\n           앳더블루 사장님은 신청곡을 형평성 있게 틀어주고 친절해요~ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[메콩타이]</td>\n",
       "      <td>\\n          매운 해물 팟타이, 나시고렝, 새우연필춘권 주문.- 매운 해물...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          store                                             review\n",
       "0         [만고쿠]  \\n          가게이름 : #만고쿠 영통점⠀위치 : 수원시 영통구 반달로7번...\n",
       "1          [츠키]  \\n          연어가 맛있어요 케이퍼도 같이 주셔서 좋았습니다. 오뎅탕은 그...\n",
       "2     [지호한방삼계탕]                            \\n          .\\n        \n",
       "3        [남문통닭]  \\n          달콤하고 맛있어요.시원한 맥주와 함께하니 잘어울리는 맛\\n  ...\n",
       "4   [993COFFEE]  \\n          경국/영통 여러분!!!!! 쥬씨말고 엄마가 정말 갈아주신듯힌 ...\n",
       "5       [라헬의부엌]  \\n          일찍 문여는 카페라 엄마들 모임하기 좋아요. 브런치 메뉴도 맛...\n",
       "6         [소담골]  \\n          팥죽  맛있다고해서 처음 가본곳입니다식당에 키오스크 기계로 선...\n",
       "7         [쿠지라]          \\n          텐동에 탄산이랑 먹으면 진짜 천국임\\n        \n",
       "8        [구스띠모]  \\n          가격대비 별로..젤라또라고하기도 그렇고 그냥 베라먹는게 나은듯...\n",
       "9         [얜시부]  \\n          처음으로 먹었을 땐 별로였는데 재료 신중히 선택하니 맛있어짐재...\n",
       "10      [물고기자리]  \\n          수지에서 시작된 물고기자리 체인점. 한 때 숙성회 무한리필이 ...\n",
       "11       [고기육심]  \\n          아파트 단지 입구에 있는 고깃집. 산책을 하다가 미친듯한 양념...\n",
       "12         [서월]  \\n          영통역 먹자골목에 있는 이자카야. 신상 이자카야가 생겼길래 궁...\n",
       "13       [짬뽕타임]               \\n          평범함탕수육 진짜 많이 줌\\n        \n",
       "14     [교동반점짬뽕]  \\n          차돌짬뽕(9000), 군만두(5000).로-칼 맛집입니다. 주...\n",
       "15       [앳더블루]  \\n           앳더블루 사장님은 신청곡을 형평성 있게 틀어주고 친절해요~ ...\n",
       "16       [메콩타이]  \\n          매운 해물 팟타이, 나시고렝, 새우연필춘권 주문.- 매운 해물..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=7'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df7 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속합니다\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링합니다\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('span', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    # 평가 정보('맛있다' 마크)를 가져옵니다.\n",
    "    #review_recommend_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__Rating RestaurantReviewItem__Rating--Ok\"})\n",
    "    \n",
    "    # 리뷰를 가져옵니다.\n",
    "    review_text_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__ReviewContent\"})\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, review_text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df7 = df7.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f917b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[장인족발608]</td>\n",
       "      <td>\\n          리쥬 쓸 생각없이 먹다가 너누맛있어서 올립니다....\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[키와마루아지]</td>\n",
       "      <td>\\n          먹고 배탈남.가게 내부 위생상태보고 배탈만 나지말자했는데, 먹...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[덕자와인]</td>\n",
       "      <td>\\n          와인 한잔 먹고싶을 때 추천하는 곳 덕자와인 특이한 메뉴들도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[누룽지]</td>\n",
       "      <td>\\n            영통에 있는 누룽지 술집! ㅋㅋ 누룽지 술때문에 종종 가는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[징기스]</td>\n",
       "      <td>\\n          양고기 모듬 세트 A (양 고기모둠 480g, 명란구이)다양한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[서윤메밀전문점]</td>\n",
       "      <td>\\n          직장인 점심 먹기에는 나쁘지 않은 곳.근처에서 점심 뭐먹지~하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[덕담오리전문점]</td>\n",
       "      <td>\\n          능이해신탕 정말 양 많네요. 남자둘 여자둘이 먹었는데 남았습니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[해물보감]</td>\n",
       "      <td>\\n          낙곱새... 라고쓰고 곱이라 읽는다.사실 낙곱새를 안먹어봐서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[프랭크서울]</td>\n",
       "      <td>\\n          기본 핫도그와 치즈, 야채치즈 먹어봄..맛있음.. 바삭하고, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[두근두근디저트]</td>\n",
       "      <td>\\n          수원 영통 마카롱 맛집 두근두근 디저트 저는 줄여서 두두디라고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[포한끼]</td>\n",
       "      <td>\\n          기름 기름볶음밥 나쁘지 않음그냥 심심할 때 가끔 가는 정도\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[찌마기]</td>\n",
       "      <td>\\n          영통역 먹자골목 뒤쪽에 위치한 조개찜 전문점. 분당을 시작으로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[대박수산]</td>\n",
       "      <td>\\n          맛있어용~~~ 점심에도 와서 먹어보고싶어요튀김도 감동이었음\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[카페포레스트]</td>\n",
       "      <td>\\n          영통 반달공원 뒤 아늑한 카페 포레스트 다녀왔어요저는 더치커피...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[샤브향]</td>\n",
       "      <td>\\n          영통홈플러스뒷쪽  먹자골목에 위치한 샤브향주차장이 넓은편이고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[뚱가네]</td>\n",
       "      <td>\\n          A set 닭갈비2 + 더덕1접시 36,000- 그동안 내 기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[디아뜰리에]</td>\n",
       "      <td>\\n          생크림 케이크가 땡겨 불시에 사 먹은 디저트 카페. 포장해온 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[호식당]</td>\n",
       "      <td>\\n          연어 빼면 먹을게 없음.근데 필자가 연어를 안 좋아함...\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[봉평메밀곤드레]</td>\n",
       "      <td>\\n          곤드레밥에 된장찌개 맛있게 먹었어요~ 옛날 집된장 맛이에요^^...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        store                                             review\n",
       "0   [장인족발608]  \\n          리쥬 쓸 생각없이 먹다가 너누맛있어서 올립니다....\\n   ...\n",
       "1    [키와마루아지]  \\n          먹고 배탈남.가게 내부 위생상태보고 배탈만 나지말자했는데, 먹...\n",
       "2      [덕자와인]  \\n          와인 한잔 먹고싶을 때 추천하는 곳 덕자와인 특이한 메뉴들도 ...\n",
       "3       [누룽지]  \\n            영통에 있는 누룽지 술집! ㅋㅋ 누룽지 술때문에 종종 가는...\n",
       "4       [징기스]  \\n          양고기 모듬 세트 A (양 고기모둠 480g, 명란구이)다양한...\n",
       "5   [서윤메밀전문점]  \\n          직장인 점심 먹기에는 나쁘지 않은 곳.근처에서 점심 뭐먹지~하...\n",
       "6   [덕담오리전문점]  \\n          능이해신탕 정말 양 많네요. 남자둘 여자둘이 먹었는데 남았습니...\n",
       "7      [해물보감]  \\n          낙곱새... 라고쓰고 곱이라 읽는다.사실 낙곱새를 안먹어봐서 ...\n",
       "8     [프랭크서울]  \\n          기본 핫도그와 치즈, 야채치즈 먹어봄..맛있음.. 바삭하고, ...\n",
       "9   [두근두근디저트]  \\n          수원 영통 마카롱 맛집 두근두근 디저트 저는 줄여서 두두디라고...\n",
       "10      [포한끼]  \\n          기름 기름볶음밥 나쁘지 않음그냥 심심할 때 가끔 가는 정도\\n...\n",
       "11      [찌마기]  \\n          영통역 먹자골목 뒤쪽에 위치한 조개찜 전문점. 분당을 시작으로...\n",
       "12     [대박수산]  \\n          맛있어용~~~ 점심에도 와서 먹어보고싶어요튀김도 감동이었음\\n...\n",
       "13   [카페포레스트]  \\n          영통 반달공원 뒤 아늑한 카페 포레스트 다녀왔어요저는 더치커피...\n",
       "14      [샤브향]  \\n          영통홈플러스뒷쪽  먹자골목에 위치한 샤브향주차장이 넓은편이고 ...\n",
       "15      [뚱가네]  \\n          A set 닭갈비2 + 더덕1접시 36,000- 그동안 내 기...\n",
       "16    [디아뜰리에]  \\n          생크림 케이크가 땡겨 불시에 사 먹은 디저트 카페. 포장해온 ...\n",
       "17      [호식당]  \\n          연어 빼면 먹을게 없음.근데 필자가 연어를 안 좋아함...\\n...\n",
       "18  [봉평메밀곤드레]  \\n          곤드레밥에 된장찌개 맛있게 먹었어요~ 옛날 집된장 맛이에요^^..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=8'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df8 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속합니다\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링합니다\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('span', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    # 평가 정보('맛있다' 마크)를 가져옵니다.\n",
    "    #review_recommend_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__Rating RestaurantReviewItem__Rating--Ok\"})\n",
    "    \n",
    "    # 리뷰를 가져옵니다.\n",
    "    review_text_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__ReviewContent\"})\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, review_text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df8 = df8.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "287e2f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[먹개비촌]</td>\n",
       "      <td>\\n          영통 먹자골목 근처에 있는 해산물 찜/찌개 요리 전문점. 게장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[포앤드]</td>\n",
       "      <td>\\n          음식이 너무 맛있어요! 기본베이스인 육수가 너무 맛있으니 음식...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[쌤순]</td>\n",
       "      <td>\\n          수원가정법원 근처에 있는 이탈리안 식당. 못보던 식당이 생겨 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[카페운트]</td>\n",
       "      <td>\\n          홈플러스 영통점 대각선 건물에 있는 카페. 간판이 따로 없고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[에베레스트레스토랑]</td>\n",
       "      <td>\\n          네팔부부가 운영하는 에베레스트 레스토랑동대문구 3번출구에서 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[청진옥]</td>\n",
       "      <td>\\n          이게 너무너무 그리웠다 ㅠㅠ슴슴한 청국장과 자극적이지 않은 물...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[바르다김선생]</td>\n",
       "      <td>\\n          삼둥이가 먹은 갈비만두로 유명하지만 사실 좀더 나중에 나온 표...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[브릭스더커피]</td>\n",
       "      <td>\\n          수원 영통역에서 10분 거리에 있는 카페. 케이크가 정말 맛있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[중앙닭발]</td>\n",
       "      <td>\\n          매콤하고 맛있었어요 서비스 계란말이도 맛있게 잘 먹었습니닼 계...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[전광수커피하우스]</td>\n",
       "      <td>\\n          모두 무뚝뚝해요.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[청산에물흐르고]</td>\n",
       "      <td>\\n          ☆☆☆☆☆‍♀️‍♀️‍♂️‍♂️‍♂️닭볶음탕해물파전두부김치좁쌀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[이자카야이틀]</td>\n",
       "      <td>\\n          불모지에 핀 꽃같은 이자카야뭐랄까…. 이자카야가 우후죽순 생기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[어풍당당]</td>\n",
       "      <td>\\n          횟집에서 다른 조개나 멍게같은 밑반찬 안먹고 회만 공략하는 스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[탕화쿵푸]</td>\n",
       "      <td>\\n          영통 먹자골목에 위치한 마라탕집. 요즘 우후죽순처럼 생기는 마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[청명북로]</td>\n",
       "      <td>\\n          오미자 에이드 정말 맛있었어요 가게가 작고 아담해서 조용히 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[청년다방]</td>\n",
       "      <td>\\n          떡볶이는 기본이 제일 맛있네요 여기는 떡볶이보다 감튀 먹으러 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[뚜레주르]</td>\n",
       "      <td>\\n          판타지움 1층에 생긴 뚜레쥬르자리도 꽤 넓고 빵 종류도 다양하...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          store                                             review\n",
       "0        [먹개비촌]  \\n          영통 먹자골목 근처에 있는 해산물 찜/찌개 요리 전문점. 게장...\n",
       "1         [포앤드]  \\n          음식이 너무 맛있어요! 기본베이스인 육수가 너무 맛있으니 음식...\n",
       "2          [쌤순]  \\n          수원가정법원 근처에 있는 이탈리안 식당. 못보던 식당이 생겨 ...\n",
       "3        [카페운트]  \\n          홈플러스 영통점 대각선 건물에 있는 카페. 간판이 따로 없고 ...\n",
       "4   [에베레스트레스토랑]  \\n          네팔부부가 운영하는 에베레스트 레스토랑동대문구 3번출구에서 가...\n",
       "5         [청진옥]  \\n          이게 너무너무 그리웠다 ㅠㅠ슴슴한 청국장과 자극적이지 않은 물...\n",
       "6      [바르다김선생]  \\n          삼둥이가 먹은 갈비만두로 유명하지만 사실 좀더 나중에 나온 표...\n",
       "7      [브릭스더커피]  \\n          수원 영통역에서 10분 거리에 있는 카페. 케이크가 정말 맛있...\n",
       "8        [중앙닭발]  \\n          매콤하고 맛있었어요 서비스 계란말이도 맛있게 잘 먹었습니닼 계...\n",
       "9    [전광수커피하우스]                    \\n          모두 무뚝뚝해요.\\n        \n",
       "10    [청산에물흐르고]  \\n          ☆☆☆☆☆‍♀️‍♀️‍♂️‍♂️‍♂️닭볶음탕해물파전두부김치좁쌀...\n",
       "11     [이자카야이틀]  \\n          불모지에 핀 꽃같은 이자카야뭐랄까…. 이자카야가 우후죽순 생기...\n",
       "12       [어풍당당]  \\n          횟집에서 다른 조개나 멍게같은 밑반찬 안먹고 회만 공략하는 스...\n",
       "13       [탕화쿵푸]  \\n          영통 먹자골목에 위치한 마라탕집. 요즘 우후죽순처럼 생기는 마...\n",
       "14       [청명북로]  \\n          오미자 에이드 정말 맛있었어요 가게가 작고 아담해서 조용히 있...\n",
       "15       [청년다방]  \\n          떡볶이는 기본이 제일 맛있네요 여기는 떡볶이보다 감튀 먹으러 ...\n",
       "16       [뚜레주르]  \\n          판타지움 1층에 생긴 뚜레쥬르자리도 꽤 넓고 빵 종류도 다양하..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=9'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df9 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속합니다\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링합니다\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('span', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    # 평가 정보('맛있다' 마크)를 가져옵니다.\n",
    "    #review_recommend_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__Rating RestaurantReviewItem__Rating--Ok\"})\n",
    "    \n",
    "    # 리뷰를 가져옵니다.\n",
    "    review_text_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__ReviewContent\"})\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, review_text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df9 = df9.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4293f30d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28344\\2187451707.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mreview_text_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreview_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mreview_text_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"RestaurantReviewItem__ReviewList\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstripe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;31m#review_text_list = review_list.find_all(\"div\", class_=\"RestaurantReviewItem__ReviewList\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m#text = \"\".join([div.get_text() for div in review_text_list])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=10'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df10 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속합니다\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링합니다\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('ul', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    # 평가 정보('맛있다' 마크)를 가져옵니다.\n",
    "    #review_recommend_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__Rating RestaurantReviewItem__Rating--Ok\"})\n",
    "    \n",
    "    # 리뷰를 가져옵니다.\n",
    "    review_text_list=[]\n",
    "    for review in review_list:\n",
    "        review_text_list.append(review.find('div',\"RestaurantReviewItem__ReviewList\" ).text,stripe())\n",
    "        #review_text_list = review_list.find_all(\"div\", class_=\"RestaurantReviewItem__ReviewList\")\n",
    "    #text = \"\".join([div.get_text() for div in review_text_list])\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df10 = df10.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 텍스트를 하나로 합칩니다.\n",
    "#text = \"\".join([div.get_text() for div in div_tags])\n",
    "\n",
    "\n",
    "\n",
    "#df10[:1]\n",
    "\n",
    "\n",
    "datamerge.to_csv( 'page10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6006095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_url = 'https://www.mangoplate.com/search/%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99?keyword=%EC%88%98%EC%9B%90%20%EC%98%81%ED%86%B5%EA%B5%AC%20%EC%98%81%ED%86%B5%EB%8F%99&page=9'\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "driver.get(source_url)\n",
    "\n",
    "driver2 = webdriver.Chrome(window_path)  # for Windows\n",
    "driver2.get(source_url)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, \"html.parser\")\n",
    "info_list = soup.find_all(name=\"div\", attrs={\"class\":\"info\"})\n",
    "page_urls = []\n",
    "page_url_base = \"https://www.mangoplate.com\"\n",
    "for index in range(0, len(info_list)):\n",
    "    info = info_list[index]\n",
    "    review_url = info.find(name=\"a\")\n",
    "    if review_url is not None:\n",
    "        page_urls.append(page_url_base + review_url.get(\"href\"))\n",
    "\n",
    "# 중복 url을 제거합니다.\n",
    "page_urls = list(set(page_urls))\n",
    "## 기존꺼\n",
    "\n",
    "columns = ['store', 'review']\n",
    "df10 = pd.DataFrame(columns=columns)\n",
    "\n",
    "#driver = webdriver.Chrome(mac_path)  # for Mac\n",
    "driver = webdriver.Chrome(window_path)  # for Windows\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    # 상세보기 페이지에 접속\n",
    "    driver.get(page_url)\n",
    "    \n",
    "    # 리뷰를 크롤링\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    #titlename= soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    review_list = soup.find(name=\"section\", attrs={\"class\":\"RestaurantReviewList\"})\n",
    "    \n",
    "    #가게 이름\n",
    "    #store_list = review_list.find_all(name=\"header\", attrs={\"class\":\"RestaurantReviewList_Header\"})\n",
    "    store_list = review_list.find_all('span', attrs={ 'class' : 'RestaurantReviewList__RestaurantName'})\n",
    "    \n",
    "    \n",
    "    # 리뷰를 가져옴\n",
    "    review_text_list = review_list.find_all(name=\"div\", attrs={\"class\":\"RestaurantReviewItem__ReviewContent\"})\n",
    "    \n",
    "    for store,  review_text in zip(store_list, review_text_list):\n",
    "        \n",
    "        row = [store, review_text.find(name=\"p\").text]\n",
    "        series = pd.Series(row, index=df.columns)\n",
    "        df10 = df10.append(series, ignore_index=True)\n",
    "        \n",
    "driver.close()\n",
    "\n",
    "\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "163bac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[낭사이공]</td>\n",
       "      <td>\\n          진짜 베트남여행온거같아여다른데서 따라할수없는 맛이네요 짱입니다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[핫토리비노카야]</td>\n",
       "      <td>\\n          파스타랑 피자 먹고 싶어서 아는 동생 꼬셔서 가게된 영통역에서...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[수원의아침]</td>\n",
       "      <td>\\n          배달도 되는 맛집이군요! 그간 여러번 시켜먹어봤지만 역시 가장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[보영만두]</td>\n",
       "      <td>\\n          만두로는 정말 유명한 곳이니 만두사진말고.. 쫄면을 소개해볼까...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[청화월]</td>\n",
       "      <td>\\n          정말 맛있다.너무너무 가성비가 좋은 맛집이고 집근처 있었으면 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>[이동간받이]</td>\n",
       "      <td>\\n           땡이네에 갔다가 웨이팅에 기겁하고, 날도 추워서 미리 서칭해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>[예랑]</td>\n",
       "      <td>\\n          주말에 랑정식을 먹었습니다. 어른 아이 포함 18명이서 좌식으...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>[요고프로즌요거트]</td>\n",
       "      <td>\\n          허니그릭볼은  꾸덕하고  치즈같은  고소한 그릭요거트에바나나에...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>[대가국수]</td>\n",
       "      <td>\\n          동네 국수집 대가국수. 간판에서도 보이듯 ‘대’식‘가’에 국수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>[영통가야밀면]</td>\n",
       "      <td>\\n          엄청나게 특별한 맛은 아니었지만 이 시릴정도로 시원했습니다! ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          store                                             review\n",
       "0        [낭사이공]  \\n          진짜 베트남여행온거같아여다른데서 따라할수없는 맛이네요 짱입니다...\n",
       "1     [핫토리비노카야]  \\n          파스타랑 피자 먹고 싶어서 아는 동생 꼬셔서 가게된 영통역에서...\n",
       "2       [수원의아침]  \\n          배달도 되는 맛집이군요! 그간 여러번 시켜먹어봤지만 역시 가장...\n",
       "3        [보영만두]  \\n          만두로는 정말 유명한 곳이니 만두사진말고.. 쫄면을 소개해볼까...\n",
       "4         [청화월]  \\n          정말 맛있다.너무너무 가성비가 좋은 맛집이고 집근처 있었으면 ...\n",
       "..          ...                                                ...\n",
       "177     [이동간받이]  \\n           땡이네에 갔다가 웨이팅에 기겁하고, 날도 추워서 미리 서칭해...\n",
       "178        [예랑]  \\n          주말에 랑정식을 먹었습니다. 어른 아이 포함 18명이서 좌식으...\n",
       "179  [요고프로즌요거트]  \\n          허니그릭볼은  꾸덕하고  치즈같은  고소한 그릭요거트에바나나에...\n",
       "180      [대가국수]  \\n          동네 국수집 대가국수. 간판에서도 보이듯 ‘대’식‘가’에 국수...\n",
       "181    [영통가야밀면]  \\n          엄청나게 특별한 맛은 아니었지만 이 시릴정도로 시원했습니다! ...\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "datamerge= pd.concat([df,df2,df3,df4,df5,df6,df7,df8,df9,df10])\n",
    "datamerge.reset_index()\n",
    "datamerge.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90be101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamerge.to_csv( 'mangoplatecrowling.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a953e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
